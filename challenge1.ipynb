{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd6e7ea0-deef-408b-bca7-0fd02e115156",
   "metadata": {},
   "source": [
    "# installing packages \n",
    "\n",
    "## Required packages are listed in requirements.txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c0f2dc2c-f454-48a7-affd-642929530b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas==2.1.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 1)) (2.1.4)\n",
      "Requirement already satisfied: scikit-learn==1.2.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 2)) (1.2.2)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas==2.1.4->-r requirements.txt (line 1)) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas==2.1.4->-r requirements.txt (line 1)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas==2.1.4->-r requirements.txt (line 1)) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas==2.1.4->-r requirements.txt (line 1)) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn==1.2.2->-r requirements.txt (line 2)) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn==1.2.2->-r requirements.txt (line 2)) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn==1.2.2->-r requirements.txt (line 2)) (2.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas==2.1.4->-r requirements.txt (line 1)) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1166e28e-96d3-4480-a9be-c2e040abdebc",
   "metadata": {},
   "source": [
    "## importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "53698fae-23d6-40b6-8a9e-7ef8f0e10a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d352b42f-cb95-4c93-820d-d92b96d6688d",
   "metadata": {},
   "source": [
    "## load a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "d3cbdd53-3862-4690-8c0b-10bf0be697d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    \"\"\"Loads dataset from a CSV file and handles missing values.\"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    return data_processing(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda2c32c-cd9e-43af-b4ed-1e6ae75ca03b",
   "metadata": {},
   "source": [
    "## data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "4deca723-b3f6-48d7-a0ba-6448072752d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processing(df):\n",
    "    df = df.dropna()\n",
    "    df = df.dropDuplicates()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f085765a-202c-436c-b4c3-5866d8616a33",
   "metadata": {},
   "source": [
    "## Extract Genre from Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "43e6d75c-4821-418b-95d4-972dce52937d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_genre(user_query, dataset):\n",
    "    \"\"\"Extracts a relevant genre keyword from the user query.\"\"\"\n",
    "    all_genres = set(dataset['genre'].str.split(',').explode().str.strip().unique())\n",
    "    detected_genre = [genre for genre in all_genres if genre.lower() in user_query.lower()]\n",
    "    return detected_genre[0] if detected_genre else None\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2f21fe-b15d-4aa8-9d9a-8ef95fd49b61",
   "metadata": {},
   "source": [
    "## Boost Space-Related Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "321b495c-12ec-4a92-a4a1-a1440759f9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def enhance_query(user_query):\n",
    "    \"\"\"Boosts space-related words in the query for better recommendations.\"\"\"\n",
    "    if \"space\" in user_query.lower():\n",
    "        user_query += \" galaxy universe planets interstellar sci-fi alien cosmos astronaut\"\n",
    "    return user_query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d656562-ce3a-463e-8376-67cbd6bb1c00",
   "metadata": {},
   "source": [
    "## Building  TF-IDF Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "96ca828b-6741-48fb-acf5-5c54f5378cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tfidf_matrix(dataset, user_query):\n",
    "    \"\"\"Builds the TF-IDF vectorizer and transforms the dataset and user query.\"\"\"\n",
    "    dataset['combined_text'] = dataset['genre'] + ' ' + dataset['overview']\n",
    "    vectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1, 2), max_features=5000)\n",
    "    tfidf_matrix = vectorizer.fit_transform(dataset['combined_text'].tolist() + [user_query])\n",
    "    return vectorizer, tfidf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8bf694-ea6e-48c9-b602-9740834b05a6",
   "metadata": {},
   "source": [
    "## Computing Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "1b5d8f01-a135-4677-b56e-9345909c57f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarity(tfidf_matrix):\n",
    "    \"\"\"Computes cosine similarity between the user query and dataset and normalizes it.\"\"\"\n",
    "    similarity_scores = cosine_similarity(tfidf_matrix[-1], tfidf_matrix[:-1]).flatten()\n",
    "    scaler = MinMaxScaler()\n",
    "    similarity_scores = scaler.fit_transform(similarity_scores.reshape(-1, 1)).flatten()\n",
    "    return similarity_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735eaee0-8e42-40c7-96f1-047bb93c946f",
   "metadata": {},
   "source": [
    "## Get Top N Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "c48655cb-615b-4976-9da9-7013fd806f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_recommendations(dataset, similarity_scores, detected_genre, top_n=5):\n",
    "    \"\"\"Gets the top N recommended movies sorted by similarity, popularity, and rating.\"\"\"\n",
    "\n",
    "    # Add similarity scores to dataset\n",
    "    dataset = dataset.copy()\n",
    "    dataset['similarity'] = similarity_scores\n",
    "\n",
    "    # Prioritize detected genre but do not eliminate other matches\n",
    "    if detected_genre:\n",
    "        dataset['genre_match'] = dataset['genre'].apply(lambda g: 1 if detected_genre in g else 0)\n",
    "    else:\n",
    "        dataset['genre_match'] = 0\n",
    "\n",
    "    # Sort based on similarity, genre match, popularity, and rating\n",
    "    recommendations = dataset.sort_values(\n",
    "        by=[ 'similarity'], \n",
    "        ascending=[ False]\n",
    "    )\n",
    "\n",
    "    return recommendations.head(top_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905b7ec9-d927-46cb-aeea-21490494fbf7",
   "metadata": {},
   "source": [
    "## Recommend Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "f75b6d58-acf6-4a4e-8965-a6a7ac6aa5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_movies(file_path, user_query, n):\n",
    "    \"\"\"Main function to generate movie recommendations.\"\"\"\n",
    "    dataset = load_data(file_path)\n",
    "\n",
    "    if not user_query.strip():\n",
    "        print(\"Error: Query cannot be empty.\")\n",
    "        return\n",
    "\n",
    "    # Enhance query for better keyword matches\n",
    "    user_query = enhance_query(user_query)\n",
    "\n",
    "    # Extract genre from user query (soft filter, not strict)\n",
    "    detected_genre = extract_genre(user_query, dataset)\n",
    "\n",
    "    if detected_genre:\n",
    "        print(\"\\n\")\n",
    "    else:\n",
    "        print(\"\\nNo specific genre detected. Searching based on full text similarity.\")\n",
    "\n",
    "    # Build TF-IDF Matrix\n",
    "    vectorizer, tfidf_matrix = build_tfidf_matrix(dataset, user_query)\n",
    "\n",
    "    # Compute Similarity\n",
    "    similarity_scores = compute_similarity(tfidf_matrix)\n",
    "\n",
    "    # Get Recommendations\n",
    "    recommendations = get_top_recommendations(dataset, similarity_scores, detected_genre, n)\n",
    "\n",
    "    # Display recommendations\n",
    "    print(\"\\nTop recommended movies:\")\n",
    "    print(recommendations[['title','similarity']].to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5b1d7a-cb2a-4859-86d8-998a4ece4f1a",
   "metadata": {},
   "source": [
    "##  Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "529fef89-4c62-4a96-9bac-2dc5664363bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your movie preference:  i like action movie set in space\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'dropDuplicates'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12764\\1908592012.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mfile_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"movie.csv\"\u001b[0m  \u001b[1;31m# Make sure the dataset file is in the same directory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0muser_query\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Enter your movie preference: \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mrecommend_movies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser_query\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12764\\2430052408.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(file_path, user_query, n)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mrecommend_movies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser_query\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;34m\"\"\"Main function to generate movie recommendations.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0muser_query\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Error: Query cannot be empty.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12764\\592969152.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;34m\"\"\"Loads dataset from a CSV file and handles missing values.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata_processing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12764\\3283845454.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdata_processing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropDuplicates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6200\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6201\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6202\u001b[0m         ):\n\u001b[0;32m   6203\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6204\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'dropDuplicates'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    file_path = \"movie.csv\"  # Make sure the dataset file is in the same directory\n",
    "    user_query = input(\"Enter your movie preference: \").strip()\n",
    "    \n",
    "    recommend_movies(file_path, user_query, n=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c5049e-1a59-466d-9c3a-b323e11bb654",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
